# ==========================================
# STEP 1: Environment Setup & Patch Injection
# ==========================================
# Run this block first, then RESTART SESSION.

import os
import re
import time

print("ğŸ—ï¸ [1/3] Building Robust Environment...")

# 1. Install System Dependencies
os.system("sudo apt-get install -y pciutils lshw zstd")

# 2. Fix Python Dependencies (Force Numpy Downgrade for PaddleOCR)
print("ğŸ”§ Locking dependencies...")
os.system("pip install paddlepaddle-gpu")
os.system("pip install 'numpy<2.0' --force-reinstall")

# 3. Install BabelDOC
if not os.path.exists('BabelDOC'):
    print("ğŸ“¦ Cloning BabelDOC...")
    os.system("git clone https://github.com/funstory-ai/BabelDOC.git")
    os.system("pip install -r BabelDOC/requirements.txt")
    os.system("pip install -e BabelDOC")

# 4. Install Ollama
print("â¬‡ï¸ Installing Ollama...")
os.system("curl -fsSL https://ollama.com/install.sh | sh")

# 5. Inject "Timeout/Retry" Patch into BabelDOC Source Code
# This prevents the "Infinite Loop" freeze on complex layout blocks.
print("ğŸ’‰ Injecting Source Code Patch...")
target_file = '/content/BabelDOC/babeldoc/translator/translator.py'

if os.path.exists(target_file):
    with open(target_file, 'r') as f:
        code = f.read()

    # The robust function with timeout and retry logic
    robust_func = """def do_llm_translate(self, text, system_prompt=None):
        import time
        max_retries = 3
        for attempt in range(max_retries):
            try:
                messages = []
                if system_prompt:
                    messages.append({"role": "system", "content": system_prompt})
                messages.append({"role": "user", "content": text})

                # [PATCH] Enforce 120s timeout to prevent hanging
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.1,
                    timeout=120
                )
                return response.choices[0].message.content
            except Exception as e:
                print(f"\\nğŸ›¡ï¸ [Shield Active] Attempt {attempt+1}/{max_retries} failed. Retrying...")
                time.sleep(2)
        
        print("âŒ [Skip] Segment too complex or corrupted. Skipping.")
        return "[Translation Failed - Skipped]"
"""
    # Regex replacement
    pattern = r"def do_llm_translate\(self, text, system_prompt=None\):[\s\S]*?return response\.choices\[0\]\.message\.content"
    new_code = re.sub(pattern, robust_func, code)
    
    with open(target_file, 'w') as f:
        f.write(new_code)
    print("âœ… Patch Injected! System is now crash-proof.")
else:
    print("âŒ Error: Source file not found.")

print("\nğŸ‰ DONE! Please RESTART SESSION now.")

# ==========================================
# STEP 2: Engine Start & Model Config
# ==========================================
# Run this after restarting session.

import subprocess
import time
import requests

print("ğŸš€ [2/3] Warming up AI Engine...")

# 1. Start Ollama Service
subprocess.run(["pkill", "ollama"])
process = subprocess.Popen(["ollama", "serve"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)

# Wait for service
print("â³ Waiting for Ollama...", end="")
for i in range(20):
    try:
        if requests.get("http://localhost:11434").status_code == 200:
            print("\nâœ… Service Online!")
            break
    except:
        time.sleep(2)
        print(".", end="")

# 2. Configure Custom Model (TranslateGemma-32k)
print("ğŸ’ Configuring Google TranslateGemma (4B)...")
subprocess.run(["ollama", "pull", "translategemma:4b"])

print("âš™ï¸ Applying WSJ Optimization Parameters...")
with open("Modelfile_wsj", "w") as f:
    f.write("FROM translategemma:4b\n")
    f.write("PARAMETER num_ctx 32768\n")      # 32k Context for stability
    f.write("PARAMETER repeat_penalty 1.2\n") # Prevent loops
    f.write("PARAMETER temperature 0.1")      # High accuracy
subprocess.run(["ollama", "create", "wsj-translator", "-f", "Modelfile_wsj"])

print("\nğŸ‰ Model 'wsj-translator' is ready!")

# ==========================================
# STEP 3: Auto-Relay Translation
# ==========================================
# Run this to start translating.

import os
import subprocess
import time
import shutil
from google.colab import files

# === CONFIG ===
BATCH_SIZE = 5    # Reset engine every 5 pages (Crucial for T4 GPU)
TOTAL_PAGES = 20  # Total pages to translate

# 1. Upload
print("ğŸ“‚ Upload PDF...")
uploaded = files.upload()
if not uploaded:
    raise SystemExit("âŒ No file uploaded")
filename = list(uploaded.keys())[0]
base_name = os.path.splitext(filename)[0]

def reset_engine():
    print("ğŸ§¹ [VRAM Cleaning] Restarting Ollama...")
    subprocess.run(["pkill", "ollama"])
    time.sleep(2)
    subprocess.Popen(["ollama", "serve"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    time.sleep(5)

print(f"\nâš”ï¸ Starting Relay: {TOTAL_PAGES} pages, batch size {BATCH_SIZE}.")

for start in range(1, TOTAL_PAGES + 1, BATCH_SIZE):
    end = min(start + BATCH_SIZE - 1, TOTAL_PAGES)
    page_range = f"{start}-{end}"
    
    # 1. Clean VRAM
    reset_engine()
    
    print(f"\nğŸš€ Processing Pages {page_range}...")
    
    # 2. Run BabelDOC
    cmd = f"""
    babeldoc \
      --files "{filename}" \
      --pages "{page_range}" \
      --openai \
      --openai-model "wsj-translator" \
      --openai-base-url "http://localhost:11434/v1" \
      --openai-api-key "ollama" \
      --lang-out zh \
      --no-auto-extract-glossary \
      --custom-system-prompt "Translate into Simplified Chinese."
    """
    exit_code = os.system(cmd)
    
    # 3. Rename and Save
    if exit_code == 0:
        original_dual = f"{base_name}.zh.dual.pdf"
        original_mono = f"{base_name}.zh.mono.pdf"
        
        new_dual = f"WSJ_Part_{page_range}_Dual.pdf"
        new_mono = f"WSJ_Part_{page_range}_Mono.pdf"
        
        if os.path.exists(original_dual):
            shutil.move(original_dual, new_dual)
            print(f"âœ… Saved: {new_dual}")
        if os.path.exists(original_mono):
            shutil.move(original_mono, new_mono)
            print(f"âœ… Saved: {new_mono}")
    else:
        print(f"âš ï¸ Error in batch {page_range}.")

print("\nğŸ Mission Complete! Download your files from the left panel.")
